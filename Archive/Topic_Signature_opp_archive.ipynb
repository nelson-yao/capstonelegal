{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup \n",
    "from IPython.display import display, HTML\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "## Read in consolidated annotations\n",
    "#annotations={}\n",
    "#annofiles=glob.glob(\"Data/opp115-parsed-annotation-1.0/*.json\")\n",
    "#print len(annofiles)\n",
    "policyFiles=glob.glob(\"/share/pub/OPP-115/sanitized_policies/*.html\")\n",
    "print(len(policyFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Read in the annotations and original policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def readAnno(filelist):\n",
    "  annotations={}\n",
    "  for filename in filelist:\n",
    "    website=re.sub(\".json\", '', os.path.basename(filename))\n",
    "    with open(filename, \"r\") as f:\n",
    "      annotations[website]=json.load(f)\n",
    "    f.close()\n",
    "  return annotations\n",
    "\n",
    "def readPolicies(filelist):\n",
    "  soups={}\n",
    "  for filename in filelist:\n",
    "    base=os.path.basename(filename).split(\"_\")[1]\n",
    "    website=re.sub(\".html\", '', base)\n",
    "    soups[website]=BeautifulSoup(open(filename, \"r\").read(), 'html.parser')\n",
    "  return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"Data/parsed-annotation-0.5.pk\", 'rb') as f:\n",
    "  annotations=pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endIndexInSegment</th>\n",
       "      <th>section</th>\n",
       "      <th>selectedText</th>\n",
       "      <th>startIndexInSegment</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153</td>\n",
       "      <td>18</td>\n",
       "      <td>promotional purpose through one of our websites</td>\n",
       "      <td>106</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201</td>\n",
       "      <td>18</td>\n",
       "      <td>or to make a purchase from the PlayStation Shop</td>\n",
       "      <td>154</td>\n",
       "      <td>Perform service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>22</td>\n",
       "      <td>Email addresses collected from consumers durin...</td>\n",
       "      <td>0</td>\n",
       "      <td>Perform service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>24</td>\n",
       "      <td>so that we may assist these customers with cur...</td>\n",
       "      <td>124</td>\n",
       "      <td>Perform service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>40</td>\n",
       "      <td>necessary to fulfill the purposes outlined in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   endIndexInSegment  section  \\\n",
       "0                153       18   \n",
       "1                201       18   \n",
       "2                226       22   \n",
       "3                200       24   \n",
       "4                159       40   \n",
       "\n",
       "                                        selectedText  startIndexInSegment  \\\n",
       "0    promotional purpose through one of our websites                  106   \n",
       "1    or to make a purchase from the PlayStation Shop                  154   \n",
       "2  Email addresses collected from consumers durin...                    0   \n",
       "3  so that we may assist these customers with cur...                  124   \n",
       "4  necessary to fulfill the purposes outlined in ...                  102   \n",
       "\n",
       "             value  \n",
       "0        Marketing  \n",
       "1  Perform service  \n",
       "2  Perform service  \n",
       "3  Perform service  \n",
       "4            Other  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[\"playstation.com\"][\"Data Retention\"]['Retention Purpose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### read in sanitized policy texts\n",
    "policySoups=readPolicies(policyFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "## make sure that the website names are the same in both dictinoaries\n",
    "test1=filter(lambda website: website in annotations.keys(), policySoups.keys())\n",
    "test2=filter(lambda website: website in policySoups.keys(), annotations.keys())\n",
    "print(len(list(test1)))\n",
    "print(len(list(test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get a list of tokens from all of the policies, with frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get the texts from beautifulsoup objects\n",
    "\n",
    "def extractTexts(soups):\n",
    "  policyTexts={}\n",
    "  for website in soups:\n",
    "    policyTexts[website]=soups[website].get_text()\n",
    "  return policyTexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## get texts from soup objects\n",
    "policyTexts=extractTexts(policySoups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## get the training and validation set \n",
    "import random\n",
    "websites=policyTexts.keys()\n",
    "seed=124\n",
    "random.seed(seed)\n",
    "trainWebsites=random.sample(websites, 105)\n",
    "valWebstes=[web for web in websites if web not in trainWebsites]\n",
    "\n",
    "trainTexts={web:policyTexts[web] for web in trainWebsites}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import itertools\n",
    "import string\n",
    "engstop=set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print (string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "\n",
    "def cleantext(rawtext, remove):\n",
    "  # remove punctuations\n",
    "  cleaned3=remove.sub(\"\", rawtext.lower())\n",
    "  return cleaned3\n",
    "\n",
    "\n",
    "def getTokens(rawtext, length, stopwords):  # length defines number of words in the token, i.e. unigrams, bigrams ec\n",
    "  punctuations = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "  if length==1:\n",
    "    cleaned=cleantext(rawtext, punctuations)\n",
    "    tokenlist=word_tokenize(cleaned)\n",
    "    tokensNoStop=[token for token in tokenlist if token not in stopwords]\n",
    "    return list(set(tokensNoStop))\n",
    "  \n",
    "  if length>=2:\n",
    "    sentenceList=sent_tokenize(rawtext)\n",
    "    sentenceClean=[cleantext(sentence, punctuations) for sentence in sentenceList]\n",
    "    unigramLists=[word_tokenize(sentence) for sentence in sentenceClean]\n",
    "    \n",
    "    bigramLists=[zip(*[sentUnigram[i::] for i in range(length)]) for sentUnigram in unigramLists]\n",
    "    bigrams=list(itertools.chain.from_iterable(bigramLists))\n",
    "    \n",
    "    return list(set(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getAllTokens(textDict, ngram, stopwords):\n",
    "  allTokens=[]\n",
    "  for website in textDict:\n",
    "    allTokens.extend(getTokens(textDict[website], ngram, stopwords))\n",
    "  return allTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Generate Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.74 s, sys: 56 ms, total: 8.8 s\n",
      "Wall time: 8.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainUnigrams=getAllTokens(trainTexts, 1, engstop)\n",
    "trainBigrams=getAllTokens(trainTexts, 2, engstop)\n",
    "trainTrigrams=getAllTokens(trainTexts, 3, engstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51734\n",
      "161586\n",
      "199155\n"
     ]
    }
   ],
   "source": [
    "## Number of UNIQUE n-grams\n",
    "print(len(trainUnigrams))\n",
    "print(len(trainBigrams))\n",
    "print(len(trainTrigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get annotation of the training documents\n",
    "trainAnno={key:annotations[key] for key in trainTexts.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" name, email address, and your friend's email address. This information is collected and used only in a manner\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hondaSoup=policySoups[\"honda.com\"]\n",
    "hondaText=hondaSoup.get_text()\n",
    "hondaText.split(\"|||\")[52][250:360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "psSoup=policySoups['playstation.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['endIndexInSegment', 'section', 'selectedText', 'startIndexInSegment',\n",
       "       'value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations['playstation.com']['First Party Collection/Use'][\"Collection Mode\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n"
     ]
    }
   ],
   "source": [
    "#print(annotations['playstation.com']['First Party Collection/Use'][\"Personal Information Type\"].keys())\n",
    "#print annotations['playstation.com']['First Party Collection/Use'][\"Personal Information Type\"][\"selectedText\"]\n",
    "\n",
    "print (annotations['playstation.com']['First Party Collection/Use'][\"Personal Information Type\"][\"startIndexInSegment\"][0])\n",
    "#print annotations['playstation.com']['First Party Collection/Use'][\"Personal Information Type\"]['endIndexInSegment'][0]\n",
    "\n",
    "textinfo=pd.DataFrame({\"selectedText\":annotations['playstation.com']['First Party Collection/Use'][\"Personal Information Type\"][\"selectedText\"],\\\n",
    "                      \"startIndexInSegment\": annotations['playstation.com']['First Party Collection/Use'][\"Personal Information Type\"][\"startIndexInSegment\"],\\\n",
    "                      \"endIndexInSegment\": annotations['playstation.com']['First Party Collection/Use'][\"Personal Information Type\"]['endIndexInSegment'],\\\n",
    "                      \"value\": annotations['playstation.com']['First Party Collection/Use'][\"Personal Information Type\"]['value']})\n",
    "\n",
    "\n",
    "textinfo=textinfo[[\"selectedText\", \"value\", \"startIndexInSegment\", \"endIndexInSegment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "psSections=psSoup.get_text().split(\"|||\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ionNetwork   In parts of North America and South America, Sony Network Entertainment America Inc. (\"SNEA\") operates Sony Online Services, a network of online games, movies, music, other media and content and communication services. PlayStation Network (\"PSN\") is one of these Sony Online Services. With a Sony Online Services or Sony Entertainment Network account, users can purchase goods and services from SNEA through Sony Online Services and may have the opportunity to participate in various network community activities. Users can register for and log into a Sony Entertainment Network account via us.playstation.com. Collection and '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psSections[6][41:680]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Determine Relevance of each sentence in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Get the index of each sentences in the policy texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Label the sentences in a policy as relevant or irrelevant\n",
    "## \n",
    "# Topic: \"Personal Information Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getSentIdx(raw):\n",
    "  allIdx={}\n",
    "  secList=raw.split(\"|||\")\n",
    "  for i in range(len(secList)):\n",
    "    try:\n",
    "      secText=secList[i]\n",
    "    except IndexError:\n",
    "      print(i)\n",
    "    secSents=sent_tokenize(secText)\n",
    "    secIdxLists=[]\n",
    "    for sent in secSents:\n",
    "      m=re.search(re.escape(sent), secText)  ## escape to account for quotes in the string\n",
    "      secIdxLists.append((sent, i, m.start(),m.end()))\n",
    "    allIdx[i]=secIdxLists\n",
    "  return allIdx\n",
    "\n",
    "def getAllIdx(textDict):\n",
    "  results={}\n",
    "  for website, text in textDict.items():\n",
    "    try:\n",
    "      senidxes=getSentIdx(text)\n",
    "      results[website]=senidxes\n",
    "    except IndexError:\n",
    "      print(website)\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.18 s, sys: 28 ms, total: 7.21 s\n",
      "Wall time: 7.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainSentIdx=getAllIdx(trainTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "endIndexInSegment                          912\n",
       "section                                      8\n",
       "selectedText           credit card information\n",
       "startIndexInSegment                        889\n",
       "value                                Financial\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test to see if the indices are correct\n",
    "trainAnno[\"playstation.com\"]['First Party Collection/Use']['Personal Information Type'].loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Collection of personal information required to access certain website services may include the collection of date of birth, name, mailing address, email address or credit card information.',\n",
       " 8,\n",
       " 709,\n",
       " 897)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSentIdx[\"playstation.com\"][8][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "187\n",
      "start index in text 873\n",
      "end index in text 896\n",
      "Length of sentence in Annotation, and raw text 23 23\n"
     ]
    }
   ],
   "source": [
    "print( re.search(\"credit card information\", trainSentIdx[\"playstation.com\"][8][3][0]).start())\n",
    "print (re.search(\"credit card information\", trainSentIdx[\"playstation.com\"][8][3][0]).end())\n",
    "\n",
    "print (\"start index in text\", 709+164)\n",
    "print (\"end index in text\", 709+187)\n",
    "\n",
    "print (\"Length of sentence in Annotation, and raw text\", 912-889, 896-873)\n",
    "\n",
    "## for playstation.com anno indices are 16 characters ahead of copurs indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WHAT WE COLLECT:   Collection of Personal Information through our Websites   We do not require that website visitors reveal any personally identifying information in order to gain general access to our websites.',\n",
       "  8,\n",
       "  0,\n",
       "  211),\n",
       " ('However, visitors who do not wish to, or are not allowed by law to share personally identifying information, may not be able to access certain areas of our websites, participate in certain activities, or make a purchase from the PlayStationShop.',\n",
       "  8,\n",
       "  212,\n",
       "  457),\n",
       " ('Although personally identifying information may be required to participate in certain promotions or features offered through our websites or to make a purchase from the PlayStationShop, participants provide this information on a voluntary basis only.',\n",
       "  8,\n",
       "  458,\n",
       "  708),\n",
       " ('Collection of personal information required to access certain website services may include the collection of date of birth, name, mailing address, email address or credit card information.',\n",
       "  8,\n",
       "  709,\n",
       "  897)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSentIdx[\"playstation.com\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endIndexInSegment                                             246\n",
      "section                                                         5\n",
      "selectedText           social security number, and account number\n",
      "startIndexInSegment                                           204\n",
      "value                                         Personal identifier\n",
      "Name: 6, dtype: object\n",
      "social security number, and account number\n",
      "\n",
      "\n",
      "Text in corpus : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('\"Personally identifiable information or personal information\" refers to any information that identifies or can be used to contact or locate you such as name, mailing address, phone number, email address, social security number, and account number.',\n",
       "  5,\n",
       "  0,\n",
       "  247),\n",
       " ('Use of certain features and tools on this Site requires that you provide us with personally identifiable information.',\n",
       "  5,\n",
       "  248,\n",
       "  365),\n",
       " ('However, you always have the option not to provide personal information by choosing not to use a particular feature.',\n",
       "  5,\n",
       "  366,\n",
       "  482)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "start index in corpus section : 204\n",
      "end index in corpus section : 246\n"
     ]
    }
   ],
   "source": [
    "## Another example:\n",
    "exampleSite=\"honda.com\"\n",
    "annoEg=trainAnno[exampleSite]['First Party Collection/Use']['Personal Information Type'].loc[6]\n",
    "print (annoEg)\n",
    "selecTextAnno=annoEg[\"selectedText\"]\n",
    "\n",
    "print (selecTextAnno)\n",
    "\n",
    "print (\"\\n\")\n",
    "corpusText=trainSentIdx[\"honda.com\"][annoEg['section']]\n",
    "print (\"Text in corpus : \")\n",
    "display(corpusText)\n",
    "\n",
    "print (\"\\n\")\n",
    "sentenceNumber=0\n",
    "corpusStart=re.search(selecTextAnno, corpusText[sentenceNumber][0]).start()\n",
    "corpusEnd= re.search(selecTextAnno, corpusText[sentenceNumber][0]).end()\n",
    "\n",
    "print (\"start index in corpus section :\", corpusText[sentenceNumber][2]+corpusStart)\n",
    "print (\"end index in corpus section :\", corpusText[sentenceNumber][2]+corpusEnd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##a third example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endIndexInSegment                                              119\n",
      "section                                                          2\n",
      "selectedText           nformation that specifically identifies you\n",
      "startIndexInSegment                                             76\n",
      "value                                 Generic personal information\n",
      "Name: 4, dtype: object\n",
      "nformation that specifically identifies you\n",
      "\n",
      "\n",
      "Text in corpus : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Subscriber Information   UpToDate never automatically collects any information that specifically identifies you such as your name, address, or e-mail address.',\n",
       "  2,\n",
       "  0,\n",
       "  158),\n",
       " ('This information is collected only when you voluntarily provide it as part of the subscription process (\"Subscriber Information\").',\n",
       "  2,\n",
       "  159,\n",
       "  289),\n",
       " ('We will ask you whenever we need Subscriber Information that identifies you or allows us to contact you.',\n",
       "  2,\n",
       "  290,\n",
       "  394)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "start index in corpus section : 68\n",
      "end index in corpus section : 111\n",
      "Annotation indices is ahead of corpus indices by 8 characters \n"
     ]
    }
   ],
   "source": [
    "## Another example:\n",
    "exampleSite=\"uptodate.com\"\n",
    "annoEg=trainAnno[exampleSite]['First Party Collection/Use']['Personal Information Type'].loc[4]\n",
    "print (annoEg)\n",
    "selecTextAnno=annoEg[\"selectedText\"]\n",
    "\n",
    "print (selecTextAnno)\n",
    "\n",
    "print (\"\\n\")\n",
    "corpusText=trainSentIdx[exampleSite][annoEg['section']]\n",
    "sentenceNumber=[idx for idx in range(len(corpusText))][0]\n",
    "\n",
    "print (\"Text in corpus : \")\n",
    "display(corpusText)\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "corpusStart=re.search(selecTextAnno, corpusText[sentenceNumber][0]).start()\n",
    "corpusEnd= re.search(selecTextAnno, corpusText[sentenceNumber][0]).end()\n",
    "\n",
    "print (\"start index in corpus section :\", corpusText[sentenceNumber][2]+corpusStart)\n",
    "print (\"end index in corpus section :\", corpusText[sentenceNumber][2]+corpusEnd)\n",
    "\n",
    "print (\"Annotation indices is ahead of corpus indices by {} characters \".format(annoEg[\"startIndexInSegment\"]-corpusStart))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAnno[exampleSite]['First Party Collection/Use']['Personal Information Type'].loc[4][\"startIndexInSegment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the sentences and put them in a convenient structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.4 s, sys: 92 ms, total: 53.5 s\n",
      "Wall time: 53.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for each selectedText in annotation, search for corresponding sentence in the corpus \n",
    "# if a selectedText is more than one sentence long, it will be discarded, since it does not provide much information\n",
    "# for the importance of words\n",
    "def labelRel(annotations, sentIdx):\n",
    "  sentlabels={}\n",
    "  for website, siteanno in annotations.items():\n",
    "    sentlabels[website]={}\n",
    "    siteSents=sentIdx[website]\n",
    "    for section, sentList in siteSents.items():\n",
    "      \n",
    "      sentlabels[website][section]=[list(sentTuple) for sentTuple in sentList]\n",
    "      for sentEntry in sentlabels[website][section]:\n",
    "        sentEntry.append([])\n",
    "\n",
    "    for category in siteanno:\n",
    "      for topic in siteanno[category]:\n",
    "        topicFrame=siteanno[category][topic]\n",
    "        for idx in topicFrame.index:\n",
    "          if topicFrame.loc[idx][\"startIndexInSegment\"]!=-1 and topicFrame.loc[idx][\"value\"]!=\"Unspecified\":\n",
    "            entry=topicFrame.loc[idx]\n",
    "            anno_start=entry[\"endIndexInSegment\"]\n",
    "            anno_end=entry[\"startIndexInSegment\"]\n",
    "            corpusSents=sentlabels[website][entry[\"section\"]]\n",
    "            for sent in corpusSents:\n",
    "              corpus_start=sent[2]\n",
    "              corpus_end=sent[3]\n",
    "              if corpus_start <=anno_start and corpus_end >= anno_end:\n",
    "                sent[4].append((category, topic, entry[\"value\"]))\n",
    "              elif  abs(corpus_start-anno_start) <20 and abs(corpus_end-anno_end)<20:\n",
    "                sent[4].append((category,topic, entry[\"value\"]))\n",
    "              elif anno_start<=corpus_start and anno_end >= corpus_end:\n",
    "                sent[4].append((category,topic, entry[\"value\"]))\n",
    "                \n",
    "                \n",
    "  return sentlabels\n",
    "\n",
    "labeledTrainSents=labelRel(trainAnno, trainSentIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As part of the privacy program, we are subject to frequent audits of our sites and other enforcement and accountability mechanisms administered independently by ESRB.', 2, 467, 633, [('Other', 'Other Type', 'Practice not covered'), ('Data Security', 'Security Measure', 'Privacy/Security program')]]\n",
      "[ 'To protect your privacy to the maximum extent possible, we have undertaken this privacy initiative and our websites have been reviewed and certified by ESRB Privacy Online to meet established online information collection and use practices. As part of the privacy program, we are subject to frequent audits of our sites and other enforcement and accountability mechanisms administered independently by ESRB.']\n"
     ]
    }
   ],
   "source": [
    "print(labeledTrainSents[\"playstation.com\"][2][2])\n",
    "egAnno=trainAnno[\"playstation.com\"]['Data Security']['Security Measure']\n",
    "print(egAnno.loc[egAnno[\"section\"]==2, \"selectedText\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Collect all the sentences , along with their topics, for ease of processing later\n",
    "### Leave out the value for now\n",
    "\n",
    "def gatherSentsTopics(labeldIdxSet):\n",
    "  topiclist=[]\n",
    "  allsentences=[]\n",
    "  for website, corpus in labeldIdxSet.items():\n",
    "    for section, sentLists in corpus.items():\n",
    "      for sent in sentLists:\n",
    "        allsentences.append([sent[0], [(item[0], item[1]) for item in sent[4] if item[0]!=\"Other\"]])\n",
    "        for item in sent[4]:\n",
    "          topiclist.append((item[0], item[1]))\n",
    "  return set(topiclist), allsentences\n",
    "\n",
    "alltopics, allSentences=gatherSentsTopics(labeledTrainSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This Privacy Policy explains what information of yours will be collected by Company when you use the Website, any mobile versions of the Website, any applications published by the Company that you download from the Website or from a third-party, and other related services (the \"Service\"), how the information will be used and how you can control the collection, correction and/or deletion of information.',\n",
       " [('First Party Collection/Use', 'Action First-Party'),\n",
       "  ('First Party Collection/Use', 'Action First-Party'),\n",
       "  ('First Party Collection/Use', 'Action First-Party'),\n",
       "  ('First Party Collection/Use', 'Does/Does Not'),\n",
       "  ('First Party Collection/Use', 'Does/Does Not'),\n",
       "  ('First Party Collection/Use', 'Does/Does Not')]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allSentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## for each topic, we get alist of related sentences and a list of unrelated sentences\n",
    "\n",
    "def getTopicRelevanceList(labeledSentences, topiclist):\n",
    "  topicSentsCollection={topic:{\"Related\":[], \"Unrelated\":[]} for topic in topiclist}\n",
    "  for entry in labeledSentences:\n",
    "    labelset=set(entry[1])\n",
    "    for topic in topiclist:\n",
    "      if topic not in labelset:\n",
    "        topicSentsCollection[topic][\"Unrelated\"].append(entry[0])\n",
    "      else:\n",
    "         topicSentsCollection[topic][\"Related\"].append(entry[0])\n",
    "          \n",
    "  results={}\n",
    "  for topic in topiclist:\n",
    "    results[topic]={}\n",
    "    results[topic][\"Related\"]=list(set(topicSentsCollection[topic][\"Related\"]))\n",
    "    results[topic][\"Unrelated\"]=list(set(topicSentsCollection[topic][\"Unrelated\"]))\n",
    "  \n",
    "  return results\n",
    "\n",
    "\n",
    "relevantSetences=getTopicRelevanceList(allSentences, alltopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You may deactivate JavaScript via your browser settings or activate it the same way.'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevantSetences[('User Choice/Control', 'Purpose')][\"Related\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate -2log(lambda) scores \n",
    "# n is the length of ngram, \n",
    "# get O11, O12, O21, and O22 counts, see Lin and Hovy paper\n",
    "from scipy.stats import binom\n",
    "def getCounts(relevantSents, ngramList, n):\n",
    "  #break each sentence to the type of ngrams\n",
    "  ngramCounts={}\n",
    "  topiclist=list(relevantSents.keys())\n",
    "  sentNgram={topic:{\"Related\":[], \"Unrelated\":[]} for topic in topiclist}\n",
    "  for topic, sentMap in relevantSents.items():\n",
    "    print(\"Setting Default for topic {}\".format(str(topic)))\n",
    "    ngramCounts.setdefault(topic, {})\n",
    "\n",
    "    for relevance, sentlist in sentMap.items():\n",
    "      for sent in sentlist:\n",
    "        sentNgram[topic][relevance].append(getTokens(sent, length=n,  stopwords=engstop))\n",
    "    #for ngram in ngramList:\n",
    "      #ngramCounts[topic].setdefault(ngram, Counter({\"O11\":0, \"O12\":0, \"O21\":0, \"O22\":0}))\n",
    "    \n",
    "  for topic, releNgrams in sentNgram.items():\n",
    "    print(\"Calculating Signature Scores for topic {}\".format(str(topic)))\n",
    "    for relSent in releNgrams[\"Related\"]:\n",
    "      for ngram in ngramList:\n",
    "        ngramCounts[topic].setdefault(ngram, Counter({\"O11\":0, \"O12\":0, \"O21\":0, \"O22\":0}))\n",
    "        if ngram in relSent:\n",
    "          ngramCounts[topic][ngram]+=Counter({\"O11\":1})\n",
    "        else:\n",
    "          ngramCounts[topic][ngram]+=Counter({\"O21\":1})\n",
    "          \n",
    "    for unrelSent in releNgrams[\"Unrelated\"]:\n",
    "      for ngram in ngramList:\n",
    "        ngramCounts[topic].setdefault(ngram, Counter({\"O11\":0, \"O12\":0, \"O21\":0, \"O22\":0}))\n",
    "        if ngram in unrelSent:\n",
    "          ngramCounts[topic][ngram]+=Counter({\"O12\":1})\n",
    "        else:\n",
    "          ngramCounts[topic][ngram]+=Counter({\"O22\":1})\n",
    "  \n",
    "  return ngramCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get the scores for Unigrams, Bigrams and Trigrams\n",
    "unigramCounts=getCounts(relevantSetences, trainUnigrams, 1)\n",
    "#bigramCounts=getCounts(relevantSetences, trainBigrams, 2)\n",
    "#bigramCounts=getCounts(relevantSetences, trainTrigrams, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate -2log(lambda) scores \n",
    "# n is the length of ngram, \n",
    "# get O11, O12, O21, and O22 counts, see Lin and Hovy paper\n",
    "from scipy.stats import binom\n",
    "def getDefault(relevantSents, ngramList, n):\n",
    "  #break each sentence to the type of ngrams\n",
    "  ngramCounts={}\n",
    "  topiclist=list(relevantSents.keys())\n",
    "  sentNgram={topic:{\"Related\":[], \"Unrelated\":[]} for topic in topiclist}\n",
    "  \n",
    "  for topic, sentMap in relevantSents.items():\n",
    "    ngramCounts.setdefault(topic, {})\n",
    "    for relevance, sentlist in sentMap.items():\n",
    "      for sent in sentlist:\n",
    "        sentNgram[topic][relevance].append(getTokens(sent, length=n,  stopwords=engstop))\n",
    "        \n",
    "    for ngram in ngramList:\n",
    "      ngramCounts[topic].setdefault(ngram, Counter({\"O11\":0, \"O12\":0, \"O21\":0, \"O22\":0}))\n",
    "  \n",
    "  return ngramCounts, sentNgram\n",
    "\n",
    "def getCountsTwo(ngramCounts, sentNgram,ngramList, n):\n",
    "\n",
    "  ngramSet=set(ngramList)\n",
    "  for topic, releNgrams in sentNgram.items():\n",
    "    print(\"Calculating Signature Scores for topic {}\".format(str(topic)))\n",
    "    for relSent in releNgrams[\"Related\"]:\n",
    "      for ngram in relSent:\n",
    "        ngramCounts[topic].setdefault(ngram, Counter({\"O11\":0, \"O12\":0, \"O21\":0, \"O22\":0}))\n",
    "        ngramCounts[topic][ngram]+=Counter({\"O11\":1})\n",
    "       \n",
    "      left=ngramSet.difference(set(relSent))\n",
    "      for otherngram in left:\n",
    "        ngramCounts[topic].setdefault(otherngram, Counter({\"O11\":0, \"O12\":0, \"O21\":0, \"O22\":0}))\n",
    "        ngramCounts[topic][otherngram]+=Counter({\"O21\":1})\n",
    "          \n",
    "    for unrelSent in releNgrams[\"Unrelated\"]:\n",
    "      for ngram in unrelSent:\n",
    "        ngramCounts[topic].setdefault(ngram, Counter({\"O11\":0, \"O12\":0, \"O21\":0, \"O22\":0}))\n",
    "        ngramCounts[topic][ngram]+=Counter({\"O12\":1})\n",
    "        \n",
    "      unrelLeft=ngramSet.difference(set(unrelSent))\n",
    "      for otherngram in unrelLeft:\n",
    "        ngramCounts[topic].setdefault(otherngram, Counter({\"O11\":0, \"O12\":0, \"O21\":0, \"O22\":0}))\n",
    "        ngramCounts[topic][otherngram]+=Counter({\"O22\":1})\n",
    "  \n",
    "  return ngramCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigramCountTemplate, sentTokens=getDefault(relevantSetences, trainUnigrams, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Signature Scores for topic ('First Party Collection/Use', 'Choice Type')\n",
      "Calculating Signature Scores for topic ('Policy Change', 'Notification Type')\n",
      "Calculating Signature Scores for topic ('User Choice/Control', 'Choice Scope')\n",
      "Calculating Signature Scores for topic ('Third Party Sharing/Collection', 'User Type')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-e0be20d6f3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unigramCounts=getCountsTwo(unigramCountTemplate, sentTokens,trainUnigrams, 1)\\n#bigramCounts=getCounts(relevantSetences, trainBigrams, 2)\\n#bigramCounts=getCounts(relevantSetences, trainTrigrams, 3)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-30cc9de66d88>\u001b[0m in \u001b[0;36mgetCountsTwo\u001b[0;34m(ngramCounts, sentNgram, ngramList, n)\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0munrelLeft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngramSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelSent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0motherngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munrelLeft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mngramCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0motherngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"O11\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"O12\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"O21\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"O22\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mngramCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motherngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"O22\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unigramCounts=getCountsTwo(unigramCountTemplate, sentTokens,trainUnigrams, 1)\n",
    "#bigramCounts=getCounts(relevantSetences, trainBigrams, 2)\n",
    "#bigramCounts=getCounts(relevantSetences, trainTrigrams, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigramCounts[('First Party Collection/Use', 'Choice Type')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 6})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "a=Counter({\"a\":4})\n",
    "a+=Counter({\"a\":2})\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'b': 3, 'a': 2})\n"
     ]
    }
   ],
   "source": [
    "a=Counter({\"a\":2, 'b':3})\n",
    "a.setdefault(\"a\",4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate -2log(lambda) scores \n",
    "# n is the length of ngram, \n",
    "# get O11, O12, O21, and O22 counts, see Lin and Hovy paper\n",
    "from scipy.stats import binom\n",
    "def getCountsV3(relevantSents, ngramList, n):\n",
    "  #break each sentence to the type of ngrams\n",
    "  ngramCounts={}\n",
    "  topiclist=list(relevantSents.keys())\n",
    "  ngramSet=set(ngramList)\n",
    "  sentNgram={topic:{\"Related\":[], \"Unrelated\":[]} for topic in topiclist}\n",
    "  \n",
    "  for topic, sentMap in relevantSents.items():\n",
    "    #print(\"Setting corpus Default for topic {}\".format(str(topic)))\n",
    "    ngramCounts.setdefault(topic, {})\n",
    "    for relevance, sentlist in sentMap.items():\n",
    "      for sent in sentlist:\n",
    "        sentNgram[topic][relevance].append(getTokens(sent, length=n,  stopwords=engstop))\n",
    "        \n",
    "    #print(\"Setting count Default for topic {}\".format(str(topic)))\n",
    "    for ngram in ngramList:\n",
    "      ngramCounts[topic].setdefault(\"O11\", Counter())\n",
    "      ngramCounts[topic].setdefault(\"O12\", Counter())\n",
    "      ngramCounts[topic].setdefault(\"O21\", Counter())\n",
    "      ngramCounts[topic].setdefault(\"O22\", Counter())\n",
    "    \n",
    "    \n",
    "  for topic, releNgrams in sentNgram.items():\n",
    "    #print(\"Calculating Signature Scores for topic {}\".format(str(topic)))\n",
    "    for relSent in releNgrams[\"Related\"]:\n",
    "      ngramCounts[topic][\"O11\"]+=Counter({ngram:1 for ngram in relSent})\n",
    "      ngramleft=ngramSet.difference(set(relSent))\n",
    "      ngramCounts[topic][\"O21\"]+=Counter({ngram:1 for ngram in ngramleft})\n",
    "      \n",
    "    for unrelSent in releNgrams[\"Unrelated\"]:\n",
    "      ngramCounts[topic][\"O12\"]+=Counter({ngram:1 for ngram in unrelSent})\n",
    "      ngramleftUnrel=ngramSet.difference(set(unrelSent))\n",
    "      ngramCounts[topic][\"O22\"]+=Counter({ngram:1 for ngram in ngramleftUnrel}) \n",
    "  \n",
    "  return ngramCounts\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
