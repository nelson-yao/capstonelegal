{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup \n",
    "from IPython.display import display, HTML\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "## Read in consolidated annotations\n",
    "#annotations={}\n",
    "#annofiles=glob.glob(\"Data/opp115-parsed-annotation-1.0/*.json\")\n",
    "#print len(annofiles)\n",
    "policyFiles=glob.glob(\"/share/pub/OPP-115/sanitized_policies/*.html\")\n",
    "print(len(policyFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  Read in the annotations and original policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def readAnno(filelist):\n",
    "  annotations={}\n",
    "  for filename in filelist:\n",
    "    website=re.sub(\".json\", '', os.path.basename(filename))\n",
    "    with open(filename, \"r\") as f:\n",
    "      annotations[website]=json.load(f)\n",
    "    f.close()\n",
    "  return annotations\n",
    "\n",
    "def readPolicies(filelist):\n",
    "  soups={}\n",
    "  for filename in filelist:\n",
    "    base=os.path.basename(filename).split(\"_\")[1]\n",
    "    website=re.sub(\".html\", '', base)\n",
    "    soups[website]=BeautifulSoup(open(filename, \"r\").read(), 'html.parser')\n",
    "  return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"Data/parsed-annotation-0.5.pk\", 'rb') as f:\n",
    "  annotations=pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endIndexInSegment</th>\n",
       "      <th>section</th>\n",
       "      <th>selectedText</th>\n",
       "      <th>startIndexInSegment</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153</td>\n",
       "      <td>18</td>\n",
       "      <td>promotional purpose through one of our websites</td>\n",
       "      <td>106</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201</td>\n",
       "      <td>18</td>\n",
       "      <td>or to make a purchase from the PlayStation Shop</td>\n",
       "      <td>154</td>\n",
       "      <td>Perform service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>22</td>\n",
       "      <td>Email addresses collected from consumers durin...</td>\n",
       "      <td>0</td>\n",
       "      <td>Perform service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>24</td>\n",
       "      <td>so that we may assist these customers with cur...</td>\n",
       "      <td>124</td>\n",
       "      <td>Perform service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>40</td>\n",
       "      <td>necessary to fulfill the purposes outlined in ...</td>\n",
       "      <td>102</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   endIndexInSegment  section  \\\n",
       "0                153       18   \n",
       "1                201       18   \n",
       "2                226       22   \n",
       "3                200       24   \n",
       "4                159       40   \n",
       "\n",
       "                                        selectedText  startIndexInSegment  \\\n",
       "0    promotional purpose through one of our websites                  106   \n",
       "1    or to make a purchase from the PlayStation Shop                  154   \n",
       "2  Email addresses collected from consumers durin...                    0   \n",
       "3  so that we may assist these customers with cur...                  124   \n",
       "4  necessary to fulfill the purposes outlined in ...                  102   \n",
       "\n",
       "             value  \n",
       "0        Marketing  \n",
       "1  Perform service  \n",
       "2  Perform service  \n",
       "3  Perform service  \n",
       "4            Other  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[\"playstation.com\"][\"Data Retention\"]['Retention Purpose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### read in sanitized policy texts\n",
    "policySoups=readPolicies(policyFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "## make sure that the website names are the same in both dictinoaries\n",
    "test1=filter(lambda website: website in annotations.keys(), policySoups.keys())\n",
    "test2=filter(lambda website: website in policySoups.keys(), annotations.keys())\n",
    "print(len(list(test1)))\n",
    "print(len(list(test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get a list of ngrams from all of the policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get the texts from beautifulsoup objects\n",
    "\n",
    "def extractTexts(soups):\n",
    "  policyTexts={}\n",
    "  for website in soups:\n",
    "    policyTexts[website]=soups[website].get_text()\n",
    "  return policyTexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## get texts from soup objects\n",
    "policyTexts=extractTexts(policySoups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## get the training and validation set \n",
    "import random\n",
    "websites=policyTexts.keys()\n",
    "seed=124\n",
    "random.seed(seed)\n",
    "trainWebsites=random.sample(websites, 105)\n",
    "valWebsites=[web for web in websites if web not in trainWebsites]\n",
    "\n",
    "trainTexts={web:policyTexts[web] for web in trainWebsites}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import itertools\n",
    "import string\n",
    "engstop=set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print (string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "\n",
    "def cleantext(rawtext):\n",
    "  # remove punctuations\n",
    "  # remove=string.punctuations\n",
    "  cleaned3=re.sub(\"\\|\",\"\", rawtext.lower())\n",
    "  return cleaned3\n",
    "\n",
    "\n",
    "def getNgrams(rawtext, length, stopwords):  # length defines number of words in the token, i.e. unigrams, bigrams ec\n",
    "  punctuations = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "  if length==1:\n",
    "    cleaned=cleantext(rawtext)\n",
    "    tokenlist=word_tokenize(cleaned)\n",
    "    tokensNoStop=[token for token in tokenlist if token not in stopwords]\n",
    "    return list(set(tokensNoStop))\n",
    "  \n",
    "  if length>=2:\n",
    "    sentenceList=sent_tokenize(rawtext)\n",
    "    sentenceClean=[cleantext(sentence) for sentence in sentenceList]\n",
    "    unigramLists=[word_tokenize(sentence) for sentence in sentenceClean]\n",
    "    \n",
    "    bigramLists=[zip(*[sentUnigram[i::] for i in range(length)]) for sentUnigram in unigramLists]\n",
    "    bigrams=list(itertools.chain.from_iterable(bigramLists))\n",
    "    \n",
    "    return list(set(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getAllTokens(textDict, ngram, stopwords):\n",
    "  allTokens=[]\n",
    "  for website in textDict:\n",
    "    allTokens.extend(getNgrams(textDict[website], ngram, stopwords))\n",
    "  return list(set(allTokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Generate Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get annotation of the training documents\n",
    "trainAnno={key:annotations[key] for key in trainTexts.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Determine Relevance of each sentence in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Get the index of each sentences in the policy texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Label the sentences in a policy as relevant or irrelevant\n",
    "## \n",
    "# Topic: \"Personal Information Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getSentIdx(raw):\n",
    "  allIdx={}\n",
    "  secList=raw.split(\"|||\")\n",
    "  for i in range(len(secList)):\n",
    "    try:\n",
    "      secText=secList[i]\n",
    "    except IndexError:\n",
    "      print(i)\n",
    "    secSents=sent_tokenize(secText)\n",
    "    secIdxLists=[]\n",
    "    for sent in secSents:\n",
    "      m=re.search(re.escape(sent), secText)  ## escape to account for quotes in the string\n",
    "      secIdxLists.append((sent, i, m.start(),m.end()))\n",
    "    allIdx[i]=secIdxLists\n",
    "  return allIdx\n",
    "\n",
    "def getAllIdx(textDict):\n",
    "  results={}\n",
    "  for website, text in textDict.items():\n",
    "    try:\n",
    "      senidxes=getSentIdx(text)\n",
    "      results[website]=senidxes\n",
    "    except IndexError:\n",
    "      print(website)\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 16 ms, total: 14.3 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainSentIdx=getAllIdx(trainTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endIndexInSegment                                              119\n",
      "section                                                          2\n",
      "selectedText           nformation that specifically identifies you\n",
      "startIndexInSegment                                             76\n",
      "value                                 Generic personal information\n",
      "Name: 4, dtype: object\n",
      "nformation that specifically identifies you\n",
      "\n",
      "\n",
      "Text in corpus : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Subscriber Information   UpToDate never automatically collects any information that specifically identifies you such as your name, address, or e-mail address.',\n",
       "  2,\n",
       "  0,\n",
       "  158),\n",
       " ('This information is collected only when you voluntarily provide it as part of the subscription process (\"Subscriber Information\").',\n",
       "  2,\n",
       "  159,\n",
       "  289),\n",
       " ('We will ask you whenever we need Subscriber Information that identifies you or allows us to contact you.',\n",
       "  2,\n",
       "  290,\n",
       "  394)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "start index in corpus section : 68\n",
      "end index in corpus section : 111\n",
      "Annotation indices is ahead of corpus indices by 8 characters \n",
      "76\n"
     ]
    }
   ],
   "source": [
    "## An example to see if indexing is correct:\n",
    "exampleSite=\"uptodate.com\"\n",
    "annoEg=trainAnno[exampleSite]['First Party Collection/Use']['Personal Information Type'].loc[4]\n",
    "print (annoEg)\n",
    "selecTextAnno=annoEg[\"selectedText\"]\n",
    "\n",
    "print (selecTextAnno)\n",
    "\n",
    "print (\"\\n\")\n",
    "corpusText=trainSentIdx[exampleSite][annoEg['section']]\n",
    "sentenceNumber=[idx for idx in range(len(corpusText))][0]\n",
    "\n",
    "print (\"Text in corpus : \")\n",
    "display(corpusText)\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "corpusStart=re.search(selecTextAnno, corpusText[sentenceNumber][0]).start()\n",
    "corpusEnd= re.search(selecTextAnno, corpusText[sentenceNumber][0]).end()\n",
    "\n",
    "print (\"start index in corpus section :\", corpusText[sentenceNumber][2]+corpusStart)\n",
    "print (\"end index in corpus section :\", corpusText[sentenceNumber][2]+corpusEnd)\n",
    "\n",
    "print (\"Annotation indices is ahead of corpus indices by {} characters \".format(annoEg[\"startIndexInSegment\"]-corpusStart))\n",
    "\n",
    "\n",
    "print (trainAnno[exampleSite]['First Party Collection/Use']['Personal Information Type'].loc[4][\"startIndexInSegment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the sentences and put them in a convenient structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 80 ms, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for each selectedText in annotation, search for corresponding sentence in the corpus \n",
    "# if a selectedText is more than one sentence long, it will be discarded, since it does not provide much information\n",
    "# for the importance of words\n",
    "def labelRel(anno, sentIdx):\n",
    "  sentlabels={}\n",
    "  for website, siteanno in anno.items():\n",
    "    sentlabels[website]={}\n",
    "    siteSents=sentIdx[website]\n",
    "    for section, sentList in siteSents.items():\n",
    "\n",
    "      sentlabels[website][section]=[list(sentTuple) for sentTuple in sentList]\n",
    "      for sentEntry in sentlabels[website][section]:\n",
    "        sentEntry.append([])\n",
    "\n",
    "    for category in siteanno:\n",
    "      for topic in siteanno[category]:\n",
    "        topicFrame=siteanno[category][topic]\n",
    "        for idx in topicFrame.index:\n",
    "          if topicFrame.loc[idx][\"startIndexInSegment\"]!=-1 and topicFrame.loc[idx][\"value\"]!=\"Unspecified\":\n",
    "            entry=topicFrame.loc[idx]\n",
    "            anno_start=entry[\"endIndexInSegment\"]\n",
    "            anno_end=entry[\"startIndexInSegment\"]\n",
    "            corpusSents=sentlabels[website][entry[\"section\"]]\n",
    "            for sent in corpusSents:\n",
    "              corpus_start=sent[2]\n",
    "              corpus_end=sent[3]\n",
    "              if corpus_start <=anno_start and corpus_end >= anno_end:\n",
    "                sent[4].append((category, topic, entry[\"value\"]))\n",
    "              elif  abs(corpus_start-anno_start) <20 and abs(corpus_end-anno_end)<20:\n",
    "                sent[4].append((category,topic, entry[\"value\"]))\n",
    "              elif anno_start<=corpus_start and anno_end >= corpus_end:\n",
    "                sent[4].append((category,topic, entry[\"value\"]))\n",
    "                \n",
    "  return sentlabels\n",
    "\n",
    "labeledTrainSents=labelRel(trainAnno, trainSentIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeledTrainSents['sheknows.com'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### Label all the sentences in all of the texts, just like in  \"labeledTrainSents\" , output to binary\n",
    "allSentIdx=getAllIdx(policyTexts)\n",
    "allLabeledSents=labelRel(annotations, allSentIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"LabeledFullSentences.pk\", 'wb') as f:\n",
    "  pickle.dump(allLabeledSents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Collect all the sentences , along with their topics, for ease of processing later\n",
    "### Leave out the value for now\n",
    "\n",
    "def gatherSentsTopics(labeldIdxSet):\n",
    "  topiclist=[]\n",
    "  allsentences=[]\n",
    "  for website, corpus in labeldIdxSet.items():\n",
    "    for section, sentLists in corpus.items():\n",
    "      for sent in sentLists:\n",
    "        allsentences.append([website, sent[0], [(item[0], item[1]) for item in sent[4] if item[0]!=\"Other\"]])\n",
    "        for item in sent[4]:\n",
    "          topiclist.append((item[0], item[1]))\n",
    "  return set(topiclist), allsentences\n",
    "\n",
    "alltopics, allLabeledSentences=gatherSentsTopics(labeledTrainSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sheknows.com',\n",
       " 'You can change the settings on your browser or Local Device Storage to prevent cookies being stored on your Local Device Storage without your explicit consent.',\n",
       " [('First Party Collection/Use', 'Choice Type'),\n",
       "  ('First Party Collection/Use', 'Choice Type'),\n",
       "  ('First Party Collection/Use', 'Choice Type'),\n",
       "  ('Third Party Sharing/Collection', 'Choice Type'),\n",
       "  ('Third Party Sharing/Collection', 'Choice Type')]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLabeledSentences[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.68 s, sys: 20 ms, total: 1.7 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## for each topic, we get alist of related sentences and a list of unrelated sentences\n",
    "\n",
    "def getTopicRelevanceList(labeledSentences, topiclist):\n",
    "  topicSentsCollection={topic:{\"Related\":[], \"Unrelated\":[]} for topic in topiclist}\n",
    "  for entry in labeledSentences:\n",
    "    labelset=set(entry[2])\n",
    "    for topic in topiclist:\n",
    "      if topic not in labelset:\n",
    "        topicSentsCollection[topic][\"Unrelated\"].append(entry[0:2])\n",
    "      else:\n",
    "         topicSentsCollection[topic][\"Related\"].append(entry[0:2])\n",
    "          \n",
    "  results={}\n",
    "  for topic in topiclist:\n",
    "    results[topic]={}\n",
    "    results[topic][\"Related\"]=topicSentsCollection[topic][\"Related\"]\n",
    "    results[topic][\"Unrelated\"]=topicSentsCollection[topic][\"Unrelated\"]\n",
    "  \n",
    "  return results\n",
    "\n",
    "relevantSetences=getTopicRelevanceList(allLabeledSentences, alltopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10417"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevantSetences[('User Choice/Control', 'Personal Information Type')][\"Related\"])+\\\n",
    "len(relevantSetences[('User Choice/Control', 'Personal Information Type')][\"Unrelated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1509\n"
     ]
    }
   ],
   "source": [
    "print(len(relevantSetences[('First Party Collection/Use', 'Does/Does Not')][\"Related\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sheknows.com',\n",
       " 'You may also \"opt-out\" of other third party programs using OBA technology on your web browser: (a) for users targeted in the United States by visiting http://www.aboutads.info/choices; (b) for users targeted in Europe by visiting http:://www.youronlinechoices.com, selecting the country where you are located; (c) for users targeted in Australia by visiting http://youronlinechoices.com.au, and selecting \"Your Ad Choices\" or \"Your Choices\" as applicable, and (d) for users targeted in Canada by visiting http://youradchoices.ca/choices.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevantSetences[('User Choice/Control', 'Purpose')][\"Related\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sheknows.com',\n",
       " ' Information We Collect    User-Provided Information: You provide us information about yourself, such as your name and email address, when you register with the Service.']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevantSetences[('First Party Collection/Use', 'User Type')]['Related'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## put all the topics and relevance labels in the \n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def embedLabels(relSent):\n",
    "  resultsDict={}\n",
    "  for topic, releSents in relSent.items():\n",
    "    for relevance, labeledSents in releSents.items():\n",
    "      for sentence in labeledSents:\n",
    "        resultsDict.setdefault(tuple(sentence), [])\n",
    "        resultsDict[tuple(sentence)].append((topic, relevance))\n",
    "      \n",
    "  results=[list(key)+[list(set(value))] for key, value in resultsDict.items()]\n",
    "  \n",
    "  return results\n",
    "\n",
    "relSentTuples=embedLabels(relevantSetences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you wish to make changes to any personal information you have provided us, or if you have any questions about what we do with your personal information, please contact us by sending an e-mail to privacy@washingtonian.com.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relSentTuples[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 64 ms, total: 12.1 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Get ngrams from the the labeled sentences\n",
    "def getNgramsSentTup(sentsRelLabels, n, stopwords):\n",
    "  ngramsList=[]\n",
    "  for sentTuple in sentsRelLabels:\n",
    "    ngrams=getNgrams(sentTuple[1], n, stopwords)\n",
    "    ngramsList.extend(ngrams)\n",
    "  return list(set(ngramsList))\n",
    "\n",
    "\n",
    "trainUnigrams=getNgramsSentTup(relSentTuples, 1, engstop)\n",
    "trainBigrams=getNgramsSentTup(relSentTuples, 2, engstop)\n",
    "trainTrigrams=getNgramsSentTup(relSentTuples, 3, engstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Index the topics and ngrams\n",
    "alltopicsList=list(alltopics)\n",
    "topicIdx={alltopicsList[n]:n for n in range(len(alltopicsList))}\n",
    "trainUnigramIdx={trainUnigrams[n]:n for n in range(len(trainUnigrams))}\n",
    "trainBigramIdx={trainBigrams[n]:n for n in range(len(trainBigrams))}\n",
    "trainTrigramIdx={trainTrigrams[n]:n for n in range(len(trainTrigrams))}\n",
    "\n",
    "## make revers index\n",
    "topicRev={topicIdx[key]:key for key in topicIdx}\n",
    "trainUnigramRev={trainUnigramIdx[key]:key for key in trainUnigramIdx.keys()}\n",
    "trainBigramRev={trainBigramIdx[key]:key for key in trainBigramIdx.keys()}\n",
    "trainTrigramRev={trainTrigramIdx[key]:key for key in trainTrigramIdx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 ms, sys: 24 ms, total: 176 ms\n",
      "Wall time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## for each sentence in relSentTuples, index the topics\n",
    "## \n",
    "def indexTopics(sentTuples, topicIdx):\n",
    "  results=[]\n",
    "  for thing in sentTuples:\n",
    "    item=thing[0:2]\n",
    "    item.append([(topicIdx[topic],rel) for topic, rel in thing[2]])\n",
    "    results.append(item)\n",
    "  return results\n",
    "\n",
    "relSentTuplesIdx=indexTopics(relSentTuples, topicIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you wish to make changes to any personal information you have provided us, or if you have any questions about what we do with your personal information, please contact us by sending an e-mail to privacy@washingtonian.com.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relSentTuplesIdx[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10231\n"
     ]
    }
   ],
   "source": [
    "print(len(relSentTuplesIdx))  ## this will be the input for the subsequent steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Signature Model \n",
    "\n",
    "### STEP 1: Calculate the scores by indexing the words and processing with numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ngram collections from the sentences collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6541\n",
      "57617\n",
      "130350\n"
     ]
    }
   ],
   "source": [
    "print(len(trainUnigrams))\n",
    "print(len(trainBigrams))\n",
    "print(len(trainTrigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.seterr(divide='warn', invalid='warn')\n",
    "def lambdaScoresNP(relSentTupAllTopics, n,topicIdxTable, ngramIdxTable, printEvery=5000):\n",
    "  # Initiate Final count Matrix\n",
    "  countresult=np.zeros([len(ngramIdxTable),len(topicIdxTable)*4])+10**-10\n",
    "  # Some lookup tables to help assign number\n",
    "  \n",
    "  totalnumber=len(relSentTupAllTopics)\n",
    "  \n",
    "  obsidx={\"O11\":0, \"O12\":1, \"O21\":2, \"O22\":3}\n",
    "  assignlabel={\"In\":{\"Related\":0, \"Unrelated\":1},\"Out\":{\"Related\":2, \"Unrelated\":3}}\n",
    "  \n",
    "  # initiate some temporary variables\n",
    "  counter=0\n",
    "  \n",
    "  # Some other things\n",
    "  \n",
    "  ngramIdxSet=set(ngramIdxTable.values())\n",
    "  ngramIdxValue=list(ngramIdxTable.values())\n",
    "  \n",
    "  for sentTuple in relSentTupAllTopics:\n",
    "    counter+=1\n",
    "    if counter%printEvery==0:\n",
    "      print(\"Processed {} sentences out of {}\".format(counter, totalnumber))\n",
    "      \n",
    "    sentNgrams=getNgrams(rawtext=sentTuple[1], length=n, stopwords=engstop)\n",
    "    \n",
    "    topicRels=sentTuple[1]\n",
    "    \n",
    "    for topic, relevance in sentTuple[2]:\n",
    "      \n",
    "      ngramIdxIN=[]\n",
    "      for ngram in sentNgrams:\n",
    "        try:\n",
    "          ngramIdxIN.append(ngramIdxTable[ngram])\n",
    "        except:\n",
    "          pass\n",
    "      \n",
    "    \n",
    "      columnIdx=np.repeat(topic*4+assignlabel[\"Out\"][relevance],len(ngramIdxTable))\n",
    "      columnIdx[ngramIdxIN]=topic*4+assignlabel[\"In\"][relevance]\n",
    "      countresult[ngramIdxValue, columnIdx]+=1\n",
    "    \n",
    "  print(\"Calculating -2lambda score\")\n",
    "  O11cols=list(range(0,len(topicIdxTable)*4,4))\n",
    "  O12cols=list(range(1,len(topicIdxTable)*4,4))\n",
    "  O21cols=list(range(2,len(topicIdxTable)*4,4))\n",
    "  O22cols=list(range(3,len(topicIdxTable)*4,4))\n",
    "  \n",
    "  O11values=countresult[:,O11cols]\n",
    "  O12values=countresult[:,O12cols]\n",
    "  O21values=countresult[:,O21cols]\n",
    "  O22values=countresult[:,O22cols]\n",
    "  \n",
    "  p1=O11values/(O11values+O12values)\n",
    "  p2=O21values/(O21values+O22values)\n",
    "  P=(O11values+O21values)/(O11values+O12values+O21values+O22values)\n",
    "  \n",
    "  #change topics back \n",
    "  lambdascore=-2*(( O11values+O21values )*np.log(P)+(O12values+O22values)*np.log(1-P)-(O11values*np.log(p1)+O12values*np.log(1-p1)+O21values*np.log(p2)+O22values*np.log(1-p2)))\n",
    "  \n",
    "  assert lambdascore.shape==(len(ngramIdxValue),len(topicIdxTable)), \"Score matrix doesn't have the right dimensions\"\n",
    "  \n",
    "  print(\"Truning Score matrx to dictionary \")\n",
    "  \n",
    "  topicReverse={topicIdxTable[key]:key for key in topicIdxTable.keys()}\n",
    "  ngramReverse={ngramIdxTable[key]:key for key in ngramIdxTable.keys()}\n",
    "  \n",
    "  finalresult={}\n",
    "  for idx in range(lambdascore.shape[1]):\n",
    "    topic=topicReverse[idx]\n",
    "    topicScores=lambdascore[:,idx]\n",
    "    finalresult.setdefault(topic, {})\n",
    "    finalresult[topic]={ngramReverse[ngramIdx]:topicScores[ngramIdx] for ngramIdx in range(lambdascore.shape[0])}\n",
    "  \n",
    "  return finalresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 sentences out of 9752\n",
      "Processed 2000 sentences out of 9752\n",
      "Processed 3000 sentences out of 9752\n",
      "Processed 4000 sentences out of 9752\n",
      "Processed 5000 sentences out of 9752\n",
      "Processed 6000 sentences out of 9752\n",
      "Processed 7000 sentences out of 9752\n",
      "Processed 8000 sentences out of 9752\n",
      "Processed 9000 sentences out of 9752\n",
      "Calculating -2lambda score\n",
      "Truning Score matrx to dictionary \n",
      "CPU times: user 8min 43s, sys: 32 ms, total: 8min 43s\n",
      "Wall time: 8min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unigramScoreNP=lambdaScoresNP(relSentsAllTopicIndexed, 1, topicIdx,trainUnigramIdx, printEvery=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 sentences out of 9752\n",
      "Processed 1000 sentences out of 9752\n",
      "Processed 1500 sentences out of 9752\n",
      "Processed 2000 sentences out of 9752\n",
      "Processed 2500 sentences out of 9752\n",
      "Processed 3000 sentences out of 9752\n",
      "Processed 3500 sentences out of 9752\n",
      "Processed 4000 sentences out of 9752\n",
      "Processed 4500 sentences out of 9752\n",
      "Processed 5000 sentences out of 9752\n",
      "Processed 5500 sentences out of 9752\n",
      "Processed 6000 sentences out of 9752\n",
      "Processed 6500 sentences out of 9752\n",
      "Processed 7000 sentences out of 9752\n",
      "Processed 7500 sentences out of 9752\n",
      "Processed 8000 sentences out of 9752\n",
      "Processed 8500 sentences out of 9752\n",
      "Processed 9000 sentences out of 9752\n",
      "Processed 9500 sentences out of 9752\n",
      "Calculating -2lambda score\n",
      "Truning Score matrx to dictionary \n",
      "CPU times: user 1h 15min 29s, sys: 520 ms, total: 1h 15min 29s\n",
      "Wall time: 1h 15min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigramScoreNP=lambdaScoresNP(relSentsAllTopicIndexed, 2, topicIdx,trainBigramIdx, printEvery=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2000 sentences out of 9752\n",
      "Processed 4000 sentences out of 9752\n",
      "Processed 6000 sentences out of 9752\n",
      "Processed 8000 sentences out of 9752\n",
      "Calculating -2lambda score\n",
      "Truning Score matrx to dictionary \n",
      "CPU times: user 2h 50min 54s, sys: 1.97 s, total: 2h 50min 56s\n",
      "Wall time: 2h 50min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trigramScoreNP=lambdaScoresNP(relSentsAllTopicIndexed, 3, topicIdx,trainTrigramIdx, printEvery=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "with open(\"/home/nyao/Results/unigramScoresNP_170312.pk\", 'wb') as f:\n",
    "  pickle.dump(unigramScoreNP ,f)\n",
    "  \n",
    "with open(\"/home/nyao/Results/bigramScoresNP_170312.pk\", \"wb\") as f:\n",
    "  pickle.dump(bigramScoreNP, f)\n",
    "\n",
    "with open(\"/home/nyao/Results/trigramScoresNP_170312.pk\", \"wb\") as f:\n",
    "  pickle.dump(trigramScoreNP, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP2 : Validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Take the output of 'labelRel'\n",
    "### label each sentence in each document with the topic, but keep only the topic\n",
    "### makes it easier for validation later on\n",
    "def labelRelTopicOnly(labeledSentsWithSections):\n",
    "  results={}\n",
    "  for website, sectionList in labeledSentsWithSections.items():\n",
    "    results[website]=[]\n",
    "    for section, sentList in sectionList.items():\n",
    "      for sentTuple in sentList:\n",
    "        results[website].append([sentTuple[0],[topicTuple[0:2] for topicTuple in sentTuple[4]] ])\n",
    "  return results\n",
    "      \n",
    "\n",
    "## Split text into features that can be used to calculate scores \n",
    "## can be used to for creating trainning or validation data\n",
    "\n",
    "def sentWithTopic(ValTextDict, ValAnnoTation):\n",
    "  sentIdx=getAllIdx(ValTextDict)\n",
    "  labelSectionIdx=labelRel(ValAnnoTation, sentIdx)\n",
    "  labelTopOnly=labelRelTopicOnly(labelSectionIdx)\n",
    "  return labelTopOnly\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### take a raw document, convert to the same output produced by 'getTopicRelevanceList'\n",
    "def text2Label(rawtext, annotationMap):\n",
    "  sentIdx=getAllIdx(rawtext)\n",
    "  anno={key:annotationMap[key] for key in rawtext.keys()}\n",
    "  labeledSents=labelRel(anno, sentIdx)\n",
    "  allTop, allLabeledSents=gatherSentsTopics(labeledSents)\n",
    "  relSents=getTopicRelevanceList(allLabeledSents, allTop)\n",
    "  relSentTup=embedLabels(relSents)\n",
    "  return relSentTup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.37 s, sys: 4 ms, total: 4.37 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valTexts={web:policyTexts[web] for web in valWebsites}\n",
    "valAnno={web: annotations[web] for web in valWebsites}\n",
    "validateRelSentsTuples=text2Label(valTexts, valAnno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('First Party Collection/Use', 'Choice Type'), 'Unrelated'),\n",
       " (('First Party Collection/Use', 'Collection Mode'), 'Unrelated'),\n",
       " (('First Party Collection/Use', 'Action First-Party'), 'Unrelated'),\n",
       " (('International and Specific Audiences', 'Audience Type'), 'Related'),\n",
       " (('Third Party Sharing/Collection', 'Choice Scope'), 'Unrelated'),\n",
       " (('First Party Collection/Use', 'Identifiability'), 'Unrelated'),\n",
       " (('User Choice/Control', 'User Type'), 'Related'),\n",
       " (('User Access, Edit and Deletion', 'Access Type'), 'Related'),\n",
       " (('User Choice/Control', 'Choice Type'), 'Related'),\n",
       " (('Third Party Sharing/Collection', 'Purpose'), 'Unrelated'),\n",
       " (('User Choice/Control', 'Choice Scope'), 'Related'),\n",
       " (('Third Party Sharing/Collection', 'Action Third Party'), 'Unrelated'),\n",
       " (('User Access, Edit and Deletion', 'Access Scope'), 'Related'),\n",
       " (('Other', 'Other Type'), 'Unrelated'),\n",
       " (('Policy Change', 'Notification Type'), 'Unrelated'),\n",
       " (('User Choice/Control', 'Personal Information Type'), 'Related'),\n",
       " (('Third Party Sharing/Collection', 'Identifiability'), 'Unrelated'),\n",
       " (('Third Party Sharing/Collection', 'Third Party Entity'), 'Unrelated'),\n",
       " (('First Party Collection/Use', 'User Type'), 'Unrelated'),\n",
       " (('User Access, Edit and Deletion', 'User Type'), 'Related'),\n",
       " (('Data Retention', 'Retention Purpose'), 'Unrelated'),\n",
       " (('User Choice/Control', 'Purpose'), 'Related'),\n",
       " (('First Party Collection/Use', 'Choice Scope'), 'Unrelated'),\n",
       " (('Policy Change', 'User Choice'), 'Unrelated'),\n",
       " (('Policy Change', 'Change Type'), 'Unrelated'),\n",
       " (('First Party Collection/Use', 'Personal Information Type'), 'Unrelated'),\n",
       " (('Third Party Sharing/Collection', 'Personal Information Type'),\n",
       "  'Unrelated'),\n",
       " (('Data Security', 'Security Measure'), 'Unrelated'),\n",
       " (('Third Party Sharing/Collection', 'Choice Type'), 'Unrelated'),\n",
       " (('Third Party Sharing/Collection', 'Does/Does Not'), 'Unrelated'),\n",
       " (('First Party Collection/Use', 'Does/Does Not'), 'Unrelated'),\n",
       " (('Data Retention', 'Personal Information Type'), 'Unrelated'),\n",
       " (('Do Not Track', 'Do Not Track policy'), 'Unrelated'),\n",
       " (('Third Party Sharing/Collection', 'User Type'), 'Unrelated'),\n",
       " (('Data Retention', 'Retention Period'), 'Unrelated'),\n",
       " (('First Party Collection/Use', 'Purpose'), 'Unrelated')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validateRelSentsTuples[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.56 s, sys: 8 ms, total: 7.56 s\n",
      "Wall time: 7.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valLabeledData=sentWithTopic(valTexts, valAnno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We do not knowingly collect Personal Information from individuals under 13 years of age.',\n",
       " [('First Party Collection/Use', 'Personal Information Type'),\n",
       "  ('First Party Collection/Use', 'Does/Does Not'),\n",
       "  ('International and Specific Audiences', 'Audience Type')]]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valLabeledData['everydayhealth.com'][120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#See which topic are in all of the texts\n",
    "def countTopicsInDoc(labeledData):\n",
    "  websiteTopics={}\n",
    "  for website, sentList in labeledData.items():\n",
    "    topicList=[]\n",
    "    for sent in sentList:\n",
    "      for topic in sent[1]:\n",
    "        topicList.append(topic)\n",
    "    websiteTopics[website]=dict(Counter(topicList))\n",
    "  return websiteTopics\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2}"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(Counter({\"a\":2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valSetTopics=countTopicsInDoc(valLabeledData)\n",
    "\n",
    "## check which topics exist in all of the docs\n",
    "## Drop any rows that have NaN\n",
    "completetopics=pd.DataFrame.from_dict(valSetTopics).dropna(axis=0, how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>austincc.edu</th>\n",
       "      <th>boardgamegeek.com</th>\n",
       "      <th>dairyqueen.com</th>\n",
       "      <th>dcccd.edu</th>\n",
       "      <th>dogbreedinfo.com</th>\n",
       "      <th>everydayhealth.com</th>\n",
       "      <th>lids.com</th>\n",
       "      <th>naturalnews.com</th>\n",
       "      <th>randomhouse.com</th>\n",
       "      <th>style.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">First Party Collection/Use</th>\n",
       "      <th>Action First-Party</th>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purpose</th>\n",
       "      <td>26.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <th>Other Type</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Third Party Sharing/Collection</th>\n",
       "      <th>Action Third Party</th>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does/Does Not</th>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Information Type</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purpose</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Entity</th>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          austincc.edu  \\\n",
       "First Party Collection/Use     Action First-Party                 27.0   \n",
       "                               Purpose                            26.0   \n",
       "Other                          Other Type                         21.0   \n",
       "Third Party Sharing/Collection Action Third Party                 17.0   \n",
       "                               Does/Does Not                      15.0   \n",
       "                               Personal Information Type          16.0   \n",
       "                               Purpose                             9.0   \n",
       "                               Third Party Entity                 15.0   \n",
       "\n",
       "                                                          boardgamegeek.com  \\\n",
       "First Party Collection/Use     Action First-Party                      14.0   \n",
       "                               Purpose                                 14.0   \n",
       "Other                          Other Type                               2.0   \n",
       "Third Party Sharing/Collection Action Third Party                      11.0   \n",
       "                               Does/Does Not                            9.0   \n",
       "                               Personal Information Type                4.0   \n",
       "                               Purpose                                  8.0   \n",
       "                               Third Party Entity                       7.0   \n",
       "\n",
       "                                                          dairyqueen.com  \\\n",
       "First Party Collection/Use     Action First-Party                   17.0   \n",
       "                               Purpose                              16.0   \n",
       "Other                          Other Type                           23.0   \n",
       "Third Party Sharing/Collection Action Third Party                   22.0   \n",
       "                               Does/Does Not                         4.0   \n",
       "                               Personal Information Type            21.0   \n",
       "                               Purpose                              25.0   \n",
       "                               Third Party Entity                   24.0   \n",
       "\n",
       "                                                          dcccd.edu  \\\n",
       "First Party Collection/Use     Action First-Party               3.0   \n",
       "                               Purpose                         12.0   \n",
       "Other                          Other Type                      12.0   \n",
       "Third Party Sharing/Collection Action Third Party               9.0   \n",
       "                               Does/Does Not                    9.0   \n",
       "                               Personal Information Type        5.0   \n",
       "                               Purpose                          6.0   \n",
       "                               Third Party Entity               6.0   \n",
       "\n",
       "                                                          dogbreedinfo.com  \\\n",
       "First Party Collection/Use     Action First-Party                      1.0   \n",
       "                               Purpose                                 2.0   \n",
       "Other                          Other Type                              4.0   \n",
       "Third Party Sharing/Collection Action Third Party                      6.0   \n",
       "                               Does/Does Not                           5.0   \n",
       "                               Personal Information Type               6.0   \n",
       "                               Purpose                                 7.0   \n",
       "                               Third Party Entity                      9.0   \n",
       "\n",
       "                                                          everydayhealth.com  \\\n",
       "First Party Collection/Use     Action First-Party                       59.0   \n",
       "                               Purpose                                  83.0   \n",
       "Other                          Other Type                               44.0   \n",
       "Third Party Sharing/Collection Action Third Party                       52.0   \n",
       "                               Does/Does Not                            50.0   \n",
       "                               Personal Information Type                36.0   \n",
       "                               Purpose                                  44.0   \n",
       "                               Third Party Entity                       75.0   \n",
       "\n",
       "                                                          lids.com  \\\n",
       "First Party Collection/Use     Action First-Party             50.0   \n",
       "                               Purpose                        77.0   \n",
       "Other                          Other Type                     27.0   \n",
       "Third Party Sharing/Collection Action Third Party             41.0   \n",
       "                               Does/Does Not                  25.0   \n",
       "                               Personal Information Type      23.0   \n",
       "                               Purpose                        36.0   \n",
       "                               Third Party Entity             46.0   \n",
       "\n",
       "                                                          naturalnews.com  \\\n",
       "First Party Collection/Use     Action First-Party                     1.0   \n",
       "                               Purpose                                1.0   \n",
       "Other                          Other Type                             5.0   \n",
       "Third Party Sharing/Collection Action Third Party                     3.0   \n",
       "                               Does/Does Not                          3.0   \n",
       "                               Personal Information Type              2.0   \n",
       "                               Purpose                                2.0   \n",
       "                               Third Party Entity                     5.0   \n",
       "\n",
       "                                                          randomhouse.com  \\\n",
       "First Party Collection/Use     Action First-Party                     102   \n",
       "                               Purpose                                106   \n",
       "Other                          Other Type                              52   \n",
       "Third Party Sharing/Collection Action Third Party                      43   \n",
       "                               Does/Does Not                           21   \n",
       "                               Personal Information Type               33   \n",
       "                               Purpose                                 39   \n",
       "                               Third Party Entity                      40   \n",
       "\n",
       "                                                          style.com  \n",
       "First Party Collection/Use     Action First-Party              32.0  \n",
       "                               Purpose                         63.0  \n",
       "Other                          Other Type                      15.0  \n",
       "Third Party Sharing/Collection Action Third Party              47.0  \n",
       "                               Does/Does Not                   37.0  \n",
       "                               Personal Information Type       26.0  \n",
       "                               Purpose                         42.0  \n",
       "                               Third Party Entity              49.0  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completetopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a list of topics that are in all of the documents \n",
    "valTopcis=[('First Party Collection/Use', 'Action First-Party'), \n",
    "          ('First Party Collection/Use', 'Purpose'),\n",
    "          ('Third Party Sharing/Collection', 'Action Third Party'), \n",
    "          ('Third Party Sharing/Collection', 'Does/Does Not'),\n",
    "          ('Third Party Sharing/Collection', 'Personal Information Type'),\n",
    "          ('Third Party Sharing/Collection', 'Purpose'),\n",
    "          ('Third Party Sharing/Collection', 'Third Party Entity')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## take a sentence and score it \n",
    "def scoreSentence(rawSent, n, stopwords, scoreMap, scoreCutoff):\n",
    "  cleanSent=re.sub(\"\\\\|\", \"\", rawSent.lower())\n",
    "  ngramList=getNgrams(cleanSent, n , stopwords)\n",
    "  totalscore=0\n",
    "  for ngram in ngramList:\n",
    "    try:\n",
    "      rawscore=scoreMap[ngram]\n",
    "      totalscore+=int(rawscore>=scoreCutoff)\n",
    "    except KeyError:\n",
    "      pass\n",
    "  return totalscore/len(ngramList)\n",
    "    \n",
    "## feed in score table of a specific topic\n",
    "## rank all the sentence in the document, can be used on external data in practice\n",
    "def rankSentencesInCorpus(rawText, cutOff,nList, topic, scoreMapList):\n",
    "  scoredSentences=[]\n",
    "  sentenceList=sent_tokenize(rawText)\n",
    "  for sentence in sentenceList:\n",
    "    cleanSent=re.sub(\"\\\\|\", \"\", sentence.lower())\n",
    "    sentScore=0\n",
    "    for i in range(len(scoreMapList)):\n",
    "      sentScore+=scoreSentence(sentence, nList[i], engstop, scoreMapList[i][topic], cutOff )\n",
    "    scoredSentences.append([cleanSent, sentScore])\n",
    "  return sorted(scoredSentences, reverse=True, key=lambda x: x[1])\n",
    "\n",
    "## feed in the output from  'sentWithTopic', calculate the scores and rank the sentences, and also keep the labels\n",
    "# \n",
    "def rankSentencesWithLabels(valSet, topic,nList,scoreCutOff,rankCutOff, *scoretableList):\n",
    "  # if a sentence ranks higher than a cut off, then it is relevant\n",
    "  fulltuples={}\n",
    "  predLabels={}  # a smplified list of [sentence, topic label, predicted topic]\n",
    "  for website, sentList in valSet.items():\n",
    "\n",
    "    sentenceScoreList=[]\n",
    "    \n",
    "    for sentTuple in sentList:\n",
    "      sentence=sentTuple[0]\n",
    "      if len(sentence.split(\" \"))>4:\n",
    "        sentResult=[sentTuple[0], sentTuple[1]]\n",
    "        sentScore=0\n",
    "        \n",
    "        for i in range(len(scoretableList)):\n",
    "          sentScore+=scoreSentence(sentence, nList[i], engstop, scoretableList[i][topic], scoreCutOff )\n",
    "        sentResult.append([topic, sentScore])\n",
    "        sentenceScoreList.append(sentResult)\n",
    "        \n",
    "    sentScoresRanked=sorted(sentenceScoreList, reverse=True, key=lambda x: x[2][1])\n",
    "    fulltuples[website]=sentScoresRanked\n",
    "    \n",
    "    sentLabelPredList=[]\n",
    "    \n",
    "    for i, sentFeatureLabel in enumerate(sentScoresRanked):\n",
    "      sentLabelPred=[sentFeatureLabel[0], int(topic in sentFeatureLabel[1]), int(i<=rankCutOff), i]\n",
    "      sentLabelPredList.append(sentLabelPred)\n",
    "    \n",
    "    predLabels[website]=sentLabelPredList\n",
    "    \n",
    "  return sentScoresRanked, predLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valSentLabeled, valSentPredVectors=rankSentencesWithLabels(valLabeledData,('First Party Collection/Use', 'Does/Does Not'), [1], 3.84, 10, unigramScoreNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_and(np.array([2,3,4])==1,np.array([4,2,1])==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## calculate accuracy for all the topics\n",
    "def getAccuracy(valLabelPred):\n",
    "  websiteAccu={}\n",
    "  for website, result in valLabelPred.items():\n",
    "    labelPred=list(zip(*result))\n",
    "    label=np.array(labelPred[1])\n",
    "    pred=np.array(labelPred[2])\n",
    "    accuracy=np.sum(label==pred)/len(label)\n",
    "    precision=np.sum(np.logical_and(label==1, pred==1))/np.sum(pred==1)\n",
    "    recall=np.sum(np.logical_and(label==1, pred==1))/np.sum(label==1)\n",
    "    websiteAccu[website]=[accuracy,precision, recall]\n",
    "  return websiteAccu\n",
    "\n",
    "def getAccuracyAlltopic(valSet, topicList, nList,scoreCutOff,rankCutOff, *scoretableList):\n",
    "  allPredTuples={}\n",
    "  allLabelPredVectors={}\n",
    "  allAccuracy={}\n",
    "  for topic in topicList:\n",
    "    allInfo,labelPred=rankSentencesWithLabels(valSet, topic,nList, scoreCutOff, rankCutOff, *scoretableList)\n",
    "    allPredTuples[topic]=allInfo\n",
    "    allLabelPredVectors[topic]=labelPred\n",
    "    allAccuracy[topic]=getAccuracy(labelPred)\n",
    "  return allPredTuples, allLabelPredVectors, allAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valAllInfo, valPredLabels, valAccuracy=getAccuracyAlltopic(valLabeledData, valTopcis, [1], 3.84, 15, unigramScoreNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valAccuracyTable=pd.DataFrame.from_dict(valAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">First Party Collection/Use</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Third Party Sharing/Collection</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Action First-Party</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Action Third Party</th>\n",
       "      <th>Does/Does Not</th>\n",
       "      <th>Personal Information Type</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Third Party Entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>austincc.edu</th>\n",
       "      <td>[0.717948717949, 0.5, 0.727272727273]</td>\n",
       "      <td>[0.538461538462, 0.3125, 0.416666666667]</td>\n",
       "      <td>[0.692307692308, 0.375, 0.75]</td>\n",
       "      <td>[0.615384615385, 0.25, 0.571428571429]</td>\n",
       "      <td>[0.641025641026, 0.25, 0.666666666667]</td>\n",
       "      <td>[0.615384615385, 0.125, 0.666666666667]</td>\n",
       "      <td>[0.641025641026, 0.25, 0.666666666667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boardgamegeek.com</th>\n",
       "      <td>[0.444444444444, 0.375, 1.0]</td>\n",
       "      <td>[0.222222222222, 0.125, 1.0]</td>\n",
       "      <td>[0.333333333333, 0.25, 1.0]</td>\n",
       "      <td>[0.388888888889, 0.3125, 1.0]</td>\n",
       "      <td>[0.222222222222, 0.125, 1.0]</td>\n",
       "      <td>[0.222222222222, 0.125, 1.0]</td>\n",
       "      <td>[0.388888888889, 0.3125, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dairyqueen.com</th>\n",
       "      <td>[0.6, 0.0, 0.0]</td>\n",
       "      <td>[0.66, 0.1875, 0.428571428571]</td>\n",
       "      <td>[0.68, 0.3125, 0.5]</td>\n",
       "      <td>[0.68, 0.0625, 0.5]</td>\n",
       "      <td>[0.64, 0.25, 0.4]</td>\n",
       "      <td>[0.68, 0.4375, 0.5]</td>\n",
       "      <td>[0.7, 0.4375, 0.538461538462]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcccd.edu</th>\n",
       "      <td>[0.6, 0.125, 1.0]</td>\n",
       "      <td>[0.457142857143, 0.125, 0.285714285714]</td>\n",
       "      <td>[0.657142857143, 0.25, 1.0]</td>\n",
       "      <td>[0.657142857143, 0.25, 1.0]</td>\n",
       "      <td>[0.542857142857, 0.0625, 0.5]</td>\n",
       "      <td>[0.6, 0.125, 1.0]</td>\n",
       "      <td>[0.6, 0.125, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dogbreedinfo.com</th>\n",
       "      <td>[0.0909090909091, 0.0909090909091, 1.0]</td>\n",
       "      <td>[0.181818181818, 0.181818181818, 1.0]</td>\n",
       "      <td>[0.272727272727, 0.272727272727, 1.0]</td>\n",
       "      <td>[0.272727272727, 0.272727272727, 1.0]</td>\n",
       "      <td>[0.454545454545, 0.454545454545, 1.0]</td>\n",
       "      <td>[0.272727272727, 0.272727272727, 1.0]</td>\n",
       "      <td>[0.363636363636, 0.363636363636, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everydayhealth.com</th>\n",
       "      <td>[0.792307692308, 0.125, 0.133333333333]</td>\n",
       "      <td>[0.746153846154, 0.1875, 0.130434782609]</td>\n",
       "      <td>[0.823076923077, 0.4375, 0.333333333333]</td>\n",
       "      <td>[0.776923076923, 0.3125, 0.217391304348]</td>\n",
       "      <td>[0.8, 0.1875, 0.1875]</td>\n",
       "      <td>[0.784615384615, 0.1875, 0.166666666667]</td>\n",
       "      <td>[0.8, 0.5625, 0.321428571429]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lids.com</th>\n",
       "      <td>[0.78125, 0.1875, 0.272727272727]</td>\n",
       "      <td>[0.760416666667, 0.5, 0.347826086957]</td>\n",
       "      <td>[0.791666666667, 0.1875, 0.3]</td>\n",
       "      <td>[0.802083333333, 0.1875, 0.333333333333]</td>\n",
       "      <td>[0.791666666667, 0.125, 0.25]</td>\n",
       "      <td>[0.822916666667, 0.3125, 0.454545454545]</td>\n",
       "      <td>[0.791666666667, 0.3125, 0.357142857143]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naturalnews.com</th>\n",
       "      <td>[0.142857142857, 0.142857142857, 1.0]</td>\n",
       "      <td>[0.142857142857, 0.142857142857, 1.0]</td>\n",
       "      <td>[0.285714285714, 0.285714285714, 1.0]</td>\n",
       "      <td>[0.285714285714, 0.285714285714, 1.0]</td>\n",
       "      <td>[0.285714285714, 0.285714285714, 1.0]</td>\n",
       "      <td>[0.142857142857, 0.142857142857, 1.0]</td>\n",
       "      <td>[0.285714285714, 0.285714285714, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomhouse.com</th>\n",
       "      <td>[0.766129032258, 0.5, 0.275862068966]</td>\n",
       "      <td>[0.741935483871, 0.5, 0.25]</td>\n",
       "      <td>[0.846774193548, 0.4375, 0.411764705882]</td>\n",
       "      <td>[0.870967741935, 0.375, 0.5]</td>\n",
       "      <td>[0.870967741935, 0.375, 0.5]</td>\n",
       "      <td>[0.83064516129, 0.375, 0.352941176471]</td>\n",
       "      <td>[0.879032258065, 0.5, 0.533333333333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>style.com</th>\n",
       "      <td>[0.833333333333, 0.4375, 0.636363636364]</td>\n",
       "      <td>[0.782051282051, 0.5, 0.470588235294]</td>\n",
       "      <td>[0.74358974359, 0.25, 0.333333333333]</td>\n",
       "      <td>[0.769230769231, 0.375, 0.428571428571]</td>\n",
       "      <td>[0.74358974359, 0.1875, 0.3]</td>\n",
       "      <td>[0.846153846154, 0.5, 0.666666666667]</td>\n",
       "      <td>[0.769230769231, 0.375, 0.428571428571]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  First Party Collection/Use  \\\n",
       "                                          Action First-Party   \n",
       "austincc.edu           [0.717948717949, 0.5, 0.727272727273]   \n",
       "boardgamegeek.com               [0.444444444444, 0.375, 1.0]   \n",
       "dairyqueen.com                               [0.6, 0.0, 0.0]   \n",
       "dcccd.edu                                  [0.6, 0.125, 1.0]   \n",
       "dogbreedinfo.com     [0.0909090909091, 0.0909090909091, 1.0]   \n",
       "everydayhealth.com   [0.792307692308, 0.125, 0.133333333333]   \n",
       "lids.com                   [0.78125, 0.1875, 0.272727272727]   \n",
       "naturalnews.com        [0.142857142857, 0.142857142857, 1.0]   \n",
       "randomhouse.com        [0.766129032258, 0.5, 0.275862068966]   \n",
       "style.com           [0.833333333333, 0.4375, 0.636363636364]   \n",
       "\n",
       "                                                              \\\n",
       "                                                     Purpose   \n",
       "austincc.edu        [0.538461538462, 0.3125, 0.416666666667]   \n",
       "boardgamegeek.com               [0.222222222222, 0.125, 1.0]   \n",
       "dairyqueen.com                [0.66, 0.1875, 0.428571428571]   \n",
       "dcccd.edu            [0.457142857143, 0.125, 0.285714285714]   \n",
       "dogbreedinfo.com       [0.181818181818, 0.181818181818, 1.0]   \n",
       "everydayhealth.com  [0.746153846154, 0.1875, 0.130434782609]   \n",
       "lids.com               [0.760416666667, 0.5, 0.347826086957]   \n",
       "naturalnews.com        [0.142857142857, 0.142857142857, 1.0]   \n",
       "randomhouse.com                  [0.741935483871, 0.5, 0.25]   \n",
       "style.com              [0.782051282051, 0.5, 0.470588235294]   \n",
       "\n",
       "                              Third Party Sharing/Collection  \\\n",
       "                                          Action Third Party   \n",
       "austincc.edu                   [0.692307692308, 0.375, 0.75]   \n",
       "boardgamegeek.com                [0.333333333333, 0.25, 1.0]   \n",
       "dairyqueen.com                           [0.68, 0.3125, 0.5]   \n",
       "dcccd.edu                        [0.657142857143, 0.25, 1.0]   \n",
       "dogbreedinfo.com       [0.272727272727, 0.272727272727, 1.0]   \n",
       "everydayhealth.com  [0.823076923077, 0.4375, 0.333333333333]   \n",
       "lids.com                       [0.791666666667, 0.1875, 0.3]   \n",
       "naturalnews.com        [0.285714285714, 0.285714285714, 1.0]   \n",
       "randomhouse.com     [0.846774193548, 0.4375, 0.411764705882]   \n",
       "style.com              [0.74358974359, 0.25, 0.333333333333]   \n",
       "\n",
       "                                                              \\\n",
       "                                               Does/Does Not   \n",
       "austincc.edu          [0.615384615385, 0.25, 0.571428571429]   \n",
       "boardgamegeek.com              [0.388888888889, 0.3125, 1.0]   \n",
       "dairyqueen.com                           [0.68, 0.0625, 0.5]   \n",
       "dcccd.edu                        [0.657142857143, 0.25, 1.0]   \n",
       "dogbreedinfo.com       [0.272727272727, 0.272727272727, 1.0]   \n",
       "everydayhealth.com  [0.776923076923, 0.3125, 0.217391304348]   \n",
       "lids.com            [0.802083333333, 0.1875, 0.333333333333]   \n",
       "naturalnews.com        [0.285714285714, 0.285714285714, 1.0]   \n",
       "randomhouse.com                 [0.870967741935, 0.375, 0.5]   \n",
       "style.com            [0.769230769231, 0.375, 0.428571428571]   \n",
       "\n",
       "                                                            \\\n",
       "                                 Personal Information Type   \n",
       "austincc.edu        [0.641025641026, 0.25, 0.666666666667]   \n",
       "boardgamegeek.com             [0.222222222222, 0.125, 1.0]   \n",
       "dairyqueen.com                           [0.64, 0.25, 0.4]   \n",
       "dcccd.edu                    [0.542857142857, 0.0625, 0.5]   \n",
       "dogbreedinfo.com     [0.454545454545, 0.454545454545, 1.0]   \n",
       "everydayhealth.com                   [0.8, 0.1875, 0.1875]   \n",
       "lids.com                     [0.791666666667, 0.125, 0.25]   \n",
       "naturalnews.com      [0.285714285714, 0.285714285714, 1.0]   \n",
       "randomhouse.com               [0.870967741935, 0.375, 0.5]   \n",
       "style.com                     [0.74358974359, 0.1875, 0.3]   \n",
       "\n",
       "                                                              \\\n",
       "                                                     Purpose   \n",
       "austincc.edu         [0.615384615385, 0.125, 0.666666666667]   \n",
       "boardgamegeek.com               [0.222222222222, 0.125, 1.0]   \n",
       "dairyqueen.com                           [0.68, 0.4375, 0.5]   \n",
       "dcccd.edu                                  [0.6, 0.125, 1.0]   \n",
       "dogbreedinfo.com       [0.272727272727, 0.272727272727, 1.0]   \n",
       "everydayhealth.com  [0.784615384615, 0.1875, 0.166666666667]   \n",
       "lids.com            [0.822916666667, 0.3125, 0.454545454545]   \n",
       "naturalnews.com        [0.142857142857, 0.142857142857, 1.0]   \n",
       "randomhouse.com       [0.83064516129, 0.375, 0.352941176471]   \n",
       "style.com              [0.846153846154, 0.5, 0.666666666667]   \n",
       "\n",
       "                                                              \n",
       "                                          Third Party Entity  \n",
       "austincc.edu          [0.641025641026, 0.25, 0.666666666667]  \n",
       "boardgamegeek.com              [0.388888888889, 0.3125, 1.0]  \n",
       "dairyqueen.com                 [0.7, 0.4375, 0.538461538462]  \n",
       "dcccd.edu                                  [0.6, 0.125, 1.0]  \n",
       "dogbreedinfo.com       [0.363636363636, 0.363636363636, 1.0]  \n",
       "everydayhealth.com             [0.8, 0.5625, 0.321428571429]  \n",
       "lids.com            [0.791666666667, 0.3125, 0.357142857143]  \n",
       "naturalnews.com        [0.285714285714, 0.285714285714, 1.0]  \n",
       "randomhouse.com        [0.879032258065, 0.5, 0.533333333333]  \n",
       "style.com            [0.769230769231, 0.375, 0.428571428571]  "
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dqRankSent=rankSentencesInCorpus(valTexts['dairyqueen.com'], 1, [1],('Third Party Sharing/Collection', 'Personal Information Type') , [unigramScoreNP])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Try supervised classification model for sentence selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Try random forest\n",
    "\n",
    "\n",
    "## Generate Training Features\n",
    "def generateXY(relSentsWithLabels, topic):\n",
    "  trainTexts=[]\n",
    "  trainLabels=[]\n",
    "  for sent in relSentsWithLabels:\n",
    "    trainTexts.append(sent[1])\n",
    "    topicTuple=[x for x in sent[2] if x[0] == topic][0]\n",
    "    trainLabels.append(int(topicTuple[1]==\"Related\"))\n",
    "  return trainTexts, trainLabels\n",
    "\n",
    "train1, labels1=generateXY(relSentTuples,('Third Party Sharing/Collection', 'Personal Information Type'))\n",
    "valtext, valLabels=generateXY(validateRelSentsTuples, ('Third Party Sharing/Collection', 'Personal Information Type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer=TfidfVectorizer(max_df=3, stop_words=\"english\")\n",
    "vectorizer.fit(train1)\n",
    "trainVec=vectorizer.transform(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valVec=vectorizer.transform(valtext)\n",
    "model = RandomForestClassifier(n_estimators=500)\n",
    "model.fit(trainVec, labels1)\n",
    "pred=model.predict(valVec)\n",
    "f1score=f1_score(valLabels, pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a list of topics that are in all of the documents \n",
    "valTopics=[('First Party Collection/Use', 'Action First-Party'), \n",
    "          ('First Party Collection/Use', 'Purpose'),\n",
    "          ('Third Party Sharing/Collection', 'Action Third Party'), \n",
    "          ('Third Party Sharing/Collection', 'Does/Does Not'),\n",
    "          ('Third Party Sharing/Collection', 'Personal Information Type'),\n",
    "          ('Third Party Sharing/Collection', 'Purpose'),\n",
    "          ('Third Party Sharing/Collection', 'Third Party Entity')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modelAndValidate(trainSentTuples, valSentTuples,topiclist, vectorizer, classifier):\n",
    "  results={}\n",
    "\n",
    "  for topic in topiclist:\n",
    "    ## fit the model\n",
    "    traintexts, trainlabels=generateXY(trainSentTuples, topic)\n",
    "    vectorizer.fit(traintexts)\n",
    "    trainCounts=vectorizer.transform(traintexts)\n",
    "    valTexts, valLabels=generateXY(valSentTuples, topic)\n",
    "    valCounts=vectorizer.transform(valTexts)\n",
    "    classifier.fit(trainCounts, trainlabels)\n",
    "    predictions=classifier.predict(valCounts)\n",
    "    f1score=f1_score(valLabels, predictions, average=\"weighted\")\n",
    "    results[topic]={\"model\":classifier, \"validation_labels\":valLabels, \"predictions\":predictions, \"f1_score\":f1score}\n",
    "    print(\"Finished modeling for topic {}\".format(topic))\n",
    "  return results, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished modeling for topic ('First Party Collection/Use', 'Action First-Party')\n",
      "Finished modeling for topic ('First Party Collection/Use', 'Purpose')\n",
      "Finished modeling for topic ('Third Party Sharing/Collection', 'Action Third Party')\n",
      "Finished modeling for topic ('Third Party Sharing/Collection', 'Does/Does Not')\n",
      "Finished modeling for topic ('Third Party Sharing/Collection', 'Personal Information Type')\n",
      "Finished modeling for topic ('Third Party Sharing/Collection', 'Purpose')\n",
      "Finished modeling for topic ('Third Party Sharing/Collection', 'Third Party Entity')\n",
      "CPU times: user 6min 4s, sys: 180 ms, total: 6min 5s\n",
      "Wall time: 6min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizerFinal=TfidfVectorizer(max_df=0.2, stop_words=\"english\")\n",
    "classifierFinal=RandomForestClassifier(n_estimators=500)\n",
    "extractionModels, fittedVectorizer =modelAndValidate(relSentTuples, validateRelSentsTuples, valTopics, vectorizerFinal, classifierFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">First Party Collection/Use</th>\n",
       "      <th>Action First-Party</th>\n",
       "      <td>0.861534</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purpose</th>\n",
       "      <td>0.809102</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Third Party Sharing/Collection</th>\n",
       "      <th>Action Third Party</th>\n",
       "      <td>0.878209</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does/Does Not</th>\n",
       "      <td>0.852496</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Information Type</th>\n",
       "      <td>0.874944</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purpose</th>\n",
       "      <td>0.879136</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third Party Entity</th>\n",
       "      <td>0.870839</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          f1_score  \\\n",
       "First Party Collection/Use     Action First-Party         0.861534   \n",
       "                               Purpose                    0.809102   \n",
       "Third Party Sharing/Collection Action Third Party         0.878209   \n",
       "                               Does/Does Not              0.852496   \n",
       "                               Personal Information Type  0.874944   \n",
       "                               Purpose                    0.879136   \n",
       "                               Third Party Entity         0.870839   \n",
       "\n",
       "                                                                                                      model  \n",
       "First Party Collection/Use     Action First-Party         (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "                               Purpose                    (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "Third Party Sharing/Collection Action Third Party         (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "                               Does/Does Not              (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "                               Personal Information Type  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "                               Purpose                    (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "                               Third Party Entity         (DecisionTreeClassifier(class_weight=None, cri...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracyTables=pd.DataFrame.from_dict(extractionModels, orient=\"index\")\n",
    "display(accuracyTables.loc[:, [\"f1_score\", \"model\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractionModelsOnly={topic:value[\"model\"] for topic, value in extractionModels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/share/pub/Results/extractionModels_randomForest_upgrade.pk\", \"wb\") as f:\n",
    "  pickle.dump([extractionModelsOnly, valTopics, fittedVectorizer], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Data Retention', 'Personal Information Type'),\n",
       " ('Data Retention', 'Retention Period'),\n",
       " ('Data Retention', 'Retention Purpose'),\n",
       " ('Data Security', 'Security Measure'),\n",
       " ('Do Not Track', 'Do Not Track policy'),\n",
       " ('First Party Collection/Use', 'Action First-Party'),\n",
       " ('First Party Collection/Use', 'Choice Scope'),\n",
       " ('First Party Collection/Use', 'Choice Type'),\n",
       " ('First Party Collection/Use', 'Collection Mode'),\n",
       " ('First Party Collection/Use', 'Does/Does Not'),\n",
       " ('First Party Collection/Use', 'Identifiability'),\n",
       " ('First Party Collection/Use', 'Personal Information Type'),\n",
       " ('First Party Collection/Use', 'Purpose'),\n",
       " ('First Party Collection/Use', 'User Type'),\n",
       " ('International and Specific Audiences', 'Audience Type'),\n",
       " ('Other', 'Other Type'),\n",
       " ('Policy Change', 'Change Type'),\n",
       " ('Policy Change', 'Notification Type'),\n",
       " ('Policy Change', 'User Choice'),\n",
       " ('Third Party Sharing/Collection', 'Action Third Party'),\n",
       " ('Third Party Sharing/Collection', 'Choice Scope'),\n",
       " ('Third Party Sharing/Collection', 'Choice Type'),\n",
       " ('Third Party Sharing/Collection', 'Does/Does Not'),\n",
       " ('Third Party Sharing/Collection', 'Identifiability'),\n",
       " ('Third Party Sharing/Collection', 'Personal Information Type'),\n",
       " ('Third Party Sharing/Collection', 'Purpose'),\n",
       " ('Third Party Sharing/Collection', 'Third Party Entity'),\n",
       " ('Third Party Sharing/Collection', 'User Type'),\n",
       " ('User Access, Edit and Deletion', 'Access Scope'),\n",
       " ('User Access, Edit and Deletion', 'Access Type'),\n",
       " ('User Access, Edit and Deletion', 'User Type'),\n",
       " ('User Choice/Control', 'Choice Scope'),\n",
       " ('User Choice/Control', 'Choice Type'),\n",
       " ('User Choice/Control', 'Personal Information Type'),\n",
       " ('User Choice/Control', 'Purpose'),\n",
       " ('User Choice/Control', 'User Type')}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltopics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual information approach (not finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 1]\n",
      " [0 0 1 ..., 0 1 1]\n",
      " [0 1 0 ..., 1 1 1]\n",
      " ..., \n",
      " [1 0 0 ..., 0 1 0]\n",
      " [1 1 0 ..., 0 0 1]\n",
      " [1 0 1 ..., 0 0 1]]\n",
      "[[0 1 0 ..., 1 0 0]\n",
      " [1 0 1 ..., 1 1 1]\n",
      " [0 0 0 ..., 1 1 1]\n",
      " ..., \n",
      " [1 0 1 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 1 0]\n",
      " [0 1 1 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "x=np.random.randint(0,2,size=(1000,200))\n",
    "y=np.random.randint(0,2,size=(1000,200))\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given matrices of 1s and 0s, row is number of observations\n",
    "# column is the number of variables , implement a function that calculates MI\n",
    "\n",
    "def MIscorePart(X,Y,xlabel, ylabel):\n",
    "  assert X.shape==Y.shape, \"Shape of the two input matrices must be the same\"\n",
    "  nrow=X.shape[0]\n",
    "  ncol=X.shape[1]\n",
    "  rightX=X==xlabel\n",
    "  rightY=Y==ylabel\n",
    "  margX=(np.sum(rightX, axis=0)+10**-10)/nrow\n",
    "  margY=(np.sum(rightY, axis=0)+10**-10)/nrow\n",
    "  \n",
    "  inter=(np.sum(np.logical_and(rightX, rightY), axis=0)+10**-10)/nrow\n",
    "  #print(margX, margY, inter)\n",
    "  #print(inter*np.log(margX*margY))\n",
    "  result=inter*np.log(inter/(margX*margY))\n",
    "  return result\n",
    "  \n",
    "\n",
    "\n",
    "def MIscore(X,Y):\n",
    "  assert X.shape==Y.shape, \"Shape of the two input matrices must be the same\"\n",
    "  nrow=X.shape[0]\n",
    "  ncol=X.shape[1]\n",
    "  part1=MIscorePart(X,Y,1,1) #x=1, y=1 \n",
    "  part2=MIscorePart(X,Y,1,0)\n",
    "  part3=MIscorePart(X,Y,0,1)\n",
    "  part4=MIscorePart(X,Y,0,0)\n",
    "  \n",
    "  score=part1+part2+part3+part4\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.seterr(divide='warn', invalid='warn')\n",
    "testresult=MIscore(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "def compareMI(X,Y):\n",
    "  scikitMI=mutual_info_score(X,Y)\n",
    "  myMI=MIscore(X,Y)\n",
    "  return np.equal(scikitMI, myMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testx=np.random.randint(0,2,10000)\n",
    "testy=np.random.randint(0,2,10000)\n",
    "\n",
    "result=compareMI(testx, testy)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#index All the Sentences, \n",
    "#for each sentences\n",
    "\n",
    "def getScoreMI(relSentsAllTopic, n,topicIdxTable, ngramIdxTable, printEvery=50000):\n",
    "  relSentsAllTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
